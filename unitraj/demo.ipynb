{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unitraj.datasets.base_dataset import BaseDataset\n",
    "\n",
    "class MoEDataset(BaseDataset):\n",
    "        def __init__(self, config=None, is_validation=False):\n",
    "            super().__init__(config, is_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check config and data loading status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Warning: cache path ./cache/nuscenes/data_samples already exists, skip \n",
      "Loaded 61 samples from data_samples/nuscenes\n",
      "Data loaded\n",
      "Total samples: 61\n",
      "Batches per epoch: 61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import build_dataset\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create config dictionary\n",
    "cfg = OmegaConf.create({\n",
    "    \"load_num_workers\": 0,  # number of workers for loading data\n",
    "    \"train_data_path\": [\"data_samples/nuscenes\"],  # list of paths to the training data\n",
    "    \"val_data_path\": [\"data_samples/nuscenes\"],  # list of paths to the validation data\n",
    "    \"cache_path\": \"./cache\",\n",
    "    \"max_data_num\": [None],  # maximum number of data for each training dataset, None means all data\n",
    "    \"starting_frame\": [0],  # history trajectory starts at this frame for each training dataset\n",
    "    \"past_len\": 21,  # history trajectory length, 2.1s\n",
    "    \"future_len\": 60,  # future trajectory length, 6s\n",
    "    \"object_type\": [\"VEHICLE\"],  # object types included in the training set\n",
    "    \"line_type\": [\"lane\", \"stop_sign\", \"road_edge\", \"road_line\", \"crosswalk\", \"speed_bump\"],  # line type to be considered in the input\n",
    "    \"masked_attributes\": [\"z_axis\", \"size\"],  # attributes to be masked in the input\n",
    "    \"trajectory_sample_interval\": 1,  # sample interval for the trajectory\n",
    "    \"only_train_on_ego\": False,  # only train on AV\n",
    "    \"center_offset_of_map\": [30.0, 0.0],  # center offset of the map\n",
    "    \"use_cache\": False,  # use cache for data loading\n",
    "    \"overwrite_cache\": False,  # overwrite existing cache\n",
    "    \"store_data_in_memory\": False,  # store data in memory\n",
    "    \"method\": {\"model_name\": \"autobot\"}\n",
    "})\n",
    "\n",
    "dataset = build_dataset(cfg)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=0, collate_fn=dataset.collate_fn)\n",
    "# Print dataset stats\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Batches per epoch: {len(dataloader)}\\n\")\n",
    "\n",
    "# Inspect batches\n",
    "for batch in dataloader:\n",
    "    inputs = batch[\"input_dict\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the content of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ego_in', 'agents_in', 'roads'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import  torch\n",
    "model_input = {}\n",
    "agents_in, agents_mask, roads = inputs['obj_trajs'], inputs['obj_trajs_mask'], inputs['map_polylines']\n",
    "ego_in = torch.gather(agents_in, 1, inputs['track_index_to_predict'].view(-1, 1, 1, 1).repeat(1, 1, *agents_in.shape[-2:])).squeeze(1)\n",
    "ego_mask = torch.gather(agents_mask, 1, inputs['track_index_to_predict'].view(-1, 1, 1).repeat(1, 1, agents_mask.shape[-1])).squeeze(1)\n",
    "agents_in = torch.cat([agents_in, agents_mask.unsqueeze(-1)], dim=-1)\n",
    "agents_in = agents_in.transpose(1, 2)\n",
    "ego_in = torch.cat([ego_in, ego_mask.unsqueeze(-1)], dim=-1)\n",
    "roads = torch.cat([inputs['map_polylines'], inputs['map_polylines_mask'].unsqueeze(-1)], dim=-1)\n",
    "model_input['ego_in'] = ego_in\n",
    "model_input['agents_in'] = agents_in\n",
    "model_input['roads'] = roads\n",
    "\n",
    "model_input.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from unitraj.models.base_model.base_model import BaseModel\n",
    "\n",
    "class MoE(BaseModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_experts = config.get('num_experts', 4)\n",
    "        self.expert_hidden_size = config.get('expert_hidden_size', 256)\n",
    "        self.gate_hidden_size = config.get('gate_hidden_size', 128)\n",
    "        self.input_size = config.get('input_size', 128)\n",
    "        self.output_size = config.get('output_size', 128)\n",
    "        \n",
    "        # Define experts\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.input_size, self.expert_hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.expert_hidden_size, self.output_size)\n",
    "            ) for _ in range(self.num_experts)\n",
    "        ])\n",
    "        \n",
    "        # Define gate network\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(self.input_size, self.gate_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.gate_hidden_size, self.num_experts),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get expert weights from gate\n",
    "        gate_outputs = self.gate(x)\n",
    "        \n",
    "        # Get outputs from each expert\n",
    "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=1)\n",
    "        \n",
    "        # Combine expert outputs weighted by gate outputs\n",
    "        final_output = torch.sum(gate_outputs.unsqueeze(-1) * expert_outputs, dim=1)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MoE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m      7\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_size\u001b[39m\u001b[38;5;124m'\u001b[39m: input_size,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_size\u001b[39m\u001b[38;5;124m'\u001b[39m: output_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgate_hidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Create model and sample input\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMoE\u001b[49m(config)\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, input_size)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Forward pass with shape checking\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MoE' is not defined"
     ]
    }
   ],
   "source": [
    "# Create sample input and instantiate model\n",
    "input_size = 10\n",
    "output_size = 5\n",
    "batch_size = 8\n",
    "\n",
    "# Create config dictionary\n",
    "config = {\n",
    "    'input_size': input_size,\n",
    "    'output_size': output_size,\n",
    "    'num_experts': 4,\n",
    "    'expert_hidden_size': 256,\n",
    "    'gate_hidden_size': 128\n",
    "}\n",
    "\n",
    "# Create model and sample input\n",
    "model = MoE(config)\n",
    "x = torch.randn(batch_size, input_size)\n",
    "\n",
    "# Forward pass with shape checking\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "\n",
    "# Check gate output shape\n",
    "gate_outputs = model.gate(x)\n",
    "print(f\"Gate outputs shape: {gate_outputs.shape}\")\n",
    "\n",
    "# Check expert outputs shape\n",
    "expert_outputs = torch.stack([expert(x) for expert in model.experts], dim=1)\n",
    "print(f\"Expert outputs shape: {expert_outputs.shape}\")\n",
    "\n",
    "# Get final output and check shape\n",
    "final_output = model(x)\n",
    "print(f\"Final output shape: {final_output.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unitraj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
